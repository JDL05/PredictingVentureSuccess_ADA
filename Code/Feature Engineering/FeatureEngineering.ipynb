{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7917d461468ce96a",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Explanation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89661898e930c7",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "id": "4bfa78658af2b407",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:33:56.615618Z",
     "start_time": "2025-01-19T19:33:49.685791Z"
    }
   },
   "source": [
    "from importnb import Notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import fuzz, process\n",
    "from transformers import pipeline\n",
    "from fuzzywuzzy import fuzz\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "import re"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/janlinzner/Library/Mobile Documents/com~apple~CloudDocs/Documents/McGill/1_Lectures/Decision Analytics (MGSC 662)/2_Coding/Exercises/venv/lib/python3.12/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "c66d297d4dfe8590",
   "metadata": {},
   "source": [
    "## Dataframe import from 'DataPreprocessing'\n",
    "Importing the required data frames from 'DataPreProcessing_Pipeline.ipynb'."
   ]
  },
  {
   "cell_type": "code",
   "id": "dcbd2b89652d5181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:08.462412Z",
     "start_time": "2025-01-19T19:33:56.622613Z"
    }
   },
   "source": [
    "with Notebook():\n",
    "    from DataPreprocessing_Pipeline import companies, funding, investors, founders"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "71cdae43ffe2a0aa",
   "metadata": {},
   "source": "## New Features: Companies <> Investment Rounds"
  },
  {
   "cell_type": "markdown",
   "id": "8a5908cd8c1250c",
   "metadata": {},
   "source": [
    "### Feature 1: Months Until First Round\n",
    "Number of months between the funding date and the first investment round. Explanation: The table 'all_rounds' has every investment round made during the existence of the companies. We already mapped the respectively funding round to the startup. "
   ]
  },
  {
   "cell_type": "code",
   "id": "a4a7239219af118",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:09.029195Z",
     "start_time": "2025-01-19T19:40:08.599593Z"
    }
   },
   "source": [
    "def calculate_months_until_first_round(company_id, founded_date):\n",
    "    rounds = funding[funding['Company ID'] == company_id]\n",
    "\n",
    "    if rounds.empty:\n",
    "        return np.nan\n",
    "\n",
    "    first_round_date = rounds['Announced Date'].min()\n",
    "\n",
    "    delta_months = (first_round_date.year - founded_date.year) * 12 + (first_round_date.month - founded_date.month)\n",
    "    return max(delta_months, 0)\n",
    "\n",
    "companies['Months until First Round'] = companies.apply(\n",
    "    lambda row: calculate_months_until_first_round(row['ID'], row['Founded Date']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "companies['Months until First Round'] = companies['Months until First Round'].fillna(-1)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "bf215a0cc3087afa",
   "metadata": {},
   "source": [
    "### Feature 2: Grant Y/N\n",
    "If the company received a Grant, they get a Yes (1). If not, a No (0). For VCs it is desirable to have a company with a Grant because it leverages the invested money as a Grant do not dilute existing shareholders."
   ]
  },
  {
   "cell_type": "code",
   "id": "7df6574e5310bc06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:09.441962Z",
     "start_time": "2025-01-19T19:40:09.033553Z"
    }
   },
   "source": [
    "def check_grant_for_company(company_id):\n",
    "    company_rounds = funding[funding['Company ID'] == company_id]\n",
    "    has_grant = any(company_rounds['Funding Type'] == 'Grant')\n",
    "    return 1 if has_grant else 0\n",
    "\n",
    "companies['Grant Y/N'] = companies['ID'].apply(check_grant_for_company)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "3269590ee3113bbd",
   "metadata": {},
   "source": [
    "### Feature 3: Last Round Type\n",
    "This feature identifies the type of the most recent funding round for each company (e.g., Seed, Series A, etc.) or assigns \"No Funding\" to companies without any funding history."
   ]
  },
  {
   "cell_type": "code",
   "id": "ea43e7b39c366cdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:09.571906Z",
     "start_time": "2025-01-19T19:40:09.545658Z"
    }
   },
   "source": [
    "# Convert the 'Announced Date' column in the funding data frame to datetime format\n",
    "funding['Announced Date'] = pd.to_datetime(funding['Announced Date'])\n",
    "\n",
    "# Sort the funding data by 'Company ID' and 'Announced Date' in ascending order\n",
    "# Then group by 'Company ID' and select the last (most recent) funding round for each company\n",
    "last_round = (\n",
    "    funding.sort_values(by=['Company ID', 'Announced Date'])\n",
    "    .groupby('Company ID')\n",
    "    .last()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "last_round = last_round[['Company ID', 'Funding Type']]\n",
    "\n",
    "# Merge the most recent funding round data into the companies DataFrame\n",
    "# Match rows on 'ID' in companies and 'Company ID' in last_round\n",
    "companies = companies.merge(\n",
    "    last_round,\n",
    "    left_on='ID',\n",
    "    right_on='Company ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "companies = companies.rename(columns={'Funding Type': 'Last Round Type'})\n",
    "\n",
    "# Drop the redundant 'Company ID' column after the merge\n",
    "companies.drop(columns=['Company ID'], inplace=True)\n",
    "\n",
    "# Fill missing values in 'Last Round Type' with 'No Funding' for companies with no funding data\n",
    "companies['Last Round Type'] = companies['Last Round Type'].fillna('No Funding')\n",
    "\n",
    "# Drop the existing 'Last Funding Type' column (if it exists) as it is replaced by the new feature\n",
    "companies.drop(columns=['Last Funding Type'], inplace=True)\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "fb5c45045975cdf2",
   "metadata": {},
   "source": [
    "### Feature 4: Acquisition Status 'Was Acquired', 'Made Acquisitions'\n",
    "- Was Acquired: A binary column (1 or 0) indicating whether the company was acquired.\n",
    "- Made Acquisitions: A binary column (1 or 0) indicating whether the company made acquisitions."
   ]
  },
  {
   "cell_type": "code",
   "id": "f661eb24a16e19f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:09.581248Z",
     "start_time": "2025-01-19T19:40:09.578767Z"
    }
   },
   "source": [
    "# Check if the 'Acquisition Status' column exists in the companies data frame\n",
    "if 'Acquisition Status' in companies.columns:\n",
    "    unique_values = companies['Acquisition Status'].dropna().unique()\n",
    "    print(unique_values)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Was Acquired' 'Made Acquisitions' 'Made Acquisitions, Was Acquired']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "a6bd0f66182483c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:09.595793Z",
     "start_time": "2025-01-19T19:40:09.591541Z"
    }
   },
   "source": [
    "# Initialize new binary columns to indicate acquisition activity\n",
    "companies['Was Acquired'] = 0\n",
    "companies['Made Acquisitions'] = 0\n",
    "\n",
    "# Set 'Was Acquired' to 1 for rows where 'Acquisition Status' is 'Was Acquired'\n",
    "companies.loc[companies['Acquisition Status'] == 'Was Acquired', 'Was Acquired'] = 1\n",
    "\n",
    "# Set 'Made Acquisitions' to 1 for rows where 'Acquisition Status' is 'Made Acquisitions'\n",
    "companies.loc[companies['Acquisition Status'] == 'Made Acquisitions', 'Made Acquisitions'] = 1\n",
    "\n",
    "# For companies with 'Acquisition Status' as 'Made Acquisitions, Was Acquired',\n",
    "# set both 'Made Acquisitions' and 'Was Acquired' to 1\n",
    "companies.loc[\n",
    "    companies['Acquisition Status'] == 'Made Acquisitions, Was Acquired',\n",
    "    ['Made Acquisitions', 'Was Acquired']\n",
    "] = 1\n",
    "\n",
    "# Drop the original 'Acquisition Status' column as it is no longer needed\n",
    "companies.drop(columns=['Acquisition Status'], inplace=True)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "63c23189af697f16",
   "metadata": {},
   "source": [
    "### Feature 5: Funding phases\n",
    "- Project Funding: Indicates whether the company received early-stage funding like Angel, Pre-Seed, or Convertible Note.\n",
    "- Startup Funding: Indicates whether the company received startup funding like Seed or Series Unknown.\n",
    "- Growth Funding: Indicates whether the company received funding for growth, such as Series A, B, or C.\n",
    "- Expansion Funding: Indicates whether the company received funding for expansion, such as Series D, E, or F.\n",
    "- Exit Funding: Indicates whether the company received exit-related funding, such as Private Equity or Post-IPO rounds."
   ]
  },
  {
   "cell_type": "code",
   "id": "827fd84149103398",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:09.617592Z",
     "start_time": "2025-01-19T19:40:09.614541Z"
    }
   },
   "source": [
    "# Check if the 'Last Round Type' column exists in the companies data frame\n",
    "if 'Last Round Type' in companies.columns:\n",
    "    # Print distinct non-null values in the 'Last Round Type' column for reference\n",
    "    distinct_funding_types = companies['Last Round Type'].dropna().unique()\n",
    "    print(distinct_funding_types)\n",
    "else:\n",
    "    # Inform the user if the 'Last Round Type' column is missing\n",
    "    print(\"The column 'Last Round Type' does not exist in the DataFrame.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Seed' 'No Funding' 'Venture - Series Unknown' 'Series A' 'Series B'\n",
      " 'Convertible Note' 'Angel' 'Post-IPO Debt' 'Private Equity' 'Pre-Seed'\n",
      " 'Grant' 'Series C' 'Series F' 'Series D' 'Post-IPO Secondary' 'Series E'\n",
      " 'Post-IPO Equity']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "db766be7a6ddcdba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:09.630643Z",
     "start_time": "2025-01-19T19:40:09.623810Z"
    }
   },
   "source": [
    "# Define new columns for different funding stages and initialize them to 0\n",
    "funding_columns = ['Project Funding', 'Startup Funding', 'Growth Funding', 'Expansion Funding', 'Exit Funding']\n",
    "for col in funding_columns:\n",
    "    companies[col] = 0\n",
    "\n",
    "# Define a mapping of funding types to their respective funding stages\n",
    "funding_mapping = {\n",
    "    'Project Funding': ['Angel', 'Pre-Seed', 'Convertible Note', 'Grant', 'Venture - Series Unknown'],\n",
    "    'Startup Funding': ['Seed', 'Venture - Series Unknown'],\n",
    "    'Growth Funding': ['Series A', 'Series B', 'Series C'],\n",
    "    'Expansion Funding': ['Series D', 'Series E', 'Series F'],\n",
    "    'Exit Funding': ['Private Equity', 'Post-IPO Secondary', 'Post-IPO Equity']\n",
    "}\n",
    "\n",
    "# Assign binary values to funding stage columns based on the 'Last Round Type'\n",
    "for funding_type, types in funding_mapping.items():\n",
    "    companies.loc[companies['Last Round Type'].isin(types), funding_type] = 1\n",
    "\n",
    "# Propagate funding stages hierarchically:\n",
    "companies.loc[companies['Exit Funding'] == 1, funding_columns[:-1]] = 1\n",
    "\n",
    "companies.loc[companies['Expansion Funding'] == 1, ['Growth Funding', 'Startup Funding', 'Project Funding']] = 1\n",
    "\n",
    "companies.loc[companies['Growth Funding'] == 1, ['Startup Funding', 'Project Funding']] = 1\n",
    "\n",
    "companies.loc[companies['Startup Funding'] == 1, 'Project Funding'] = 1"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "1b29b9fa",
   "metadata": {},
   "source": [
    "### Feature 6: HighFunding (Series B or higher)\n",
    "High Funding: A binary indicator where...\n",
    "\n",
    "- 1 indicates the company participated in a high funding round (e.g., Series B or above, Private Equity, or Post-IPO rounds).\n",
    "- 0 indicates the company did not participate in these rounds."
   ]
  },
  {
   "cell_type": "code",
   "id": "35a1001a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:09.644228Z",
     "start_time": "2025-01-19T19:40:09.641065Z"
    }
   },
   "source": [
    "high_funding_rounds = ['Series B', 'Series C', 'Series D', 'Series E', 'Series F', 'Private Equity', 'Post-IPO Equity']\n",
    "companies['High Funding'] = companies['Last Round Type'].isin(high_funding_rounds).astype(int)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "73a3f39e73ec7b0c",
   "metadata": {},
   "source": [
    "### Feature 7: Average Time To Next Round\n",
    "The average time (in months) between funding events for a company, including the time from founding to the first funding round.\n",
    "\n",
    "Value:\n",
    "- -1: No valid funding data is available.\n",
    "- x: Average time in months between funding rounds."
   ]
  },
  {
   "cell_type": "code",
   "id": "c6c722f5c6e581e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:10.156787Z",
     "start_time": "2025-01-19T19:40:09.661514Z"
    }
   },
   "source": [
    "# Convert the 'Announced Date' column in the funding data frame to datetime format\n",
    "funding['Announced Date'] = pd.to_datetime(funding['Announced Date'])\n",
    "\n",
    "# Convert the 'Founded Date' column in the companies data frame to datetime format\n",
    "companies['Founded Date'] = pd.to_datetime(companies['Founded Date'])\n",
    "\n",
    "# Define a function to calculate the average time (in months) to the next funding round for a company\n",
    "def calculate_avg_time_to_next_round(company_id, company_founded_date, funding_df):\n",
    "    # Filter funding data for the specific company\n",
    "    company_funding = funding_df[funding_df['Company ID'] == company_id]\n",
    "\n",
    "    # Case 1: Only one funding round exists\n",
    "    if len(company_funding) == 1:\n",
    "        # Calculate time difference between the funding round and the founding date\n",
    "        time_diff = (company_funding['Announced Date'].iloc[0] - company_founded_date).days\n",
    "        avg_time_to_next_round = time_diff / 30  # Convert days to months\n",
    "\n",
    "    # Case 2: Two or more funding rounds exist\n",
    "    elif len(company_funding) >= 2:\n",
    "        time_diffs = []\n",
    "\n",
    "        # Calculate time difference between the first funding round and founding date\n",
    "        first_round_diff = (company_funding['Announced Date'].iloc[0] - company_founded_date).days\n",
    "        time_diffs.append(first_round_diff)\n",
    "\n",
    "        # Sort funding rounds by their announcement date\n",
    "        company_funding = company_funding.sort_values('Announced Date')\n",
    "\n",
    "        # Calculate time differences between consecutive funding rounds\n",
    "        for i in range(1, len(company_funding)):\n",
    "            time_diff = (company_funding['Announced Date'].iloc[i] - company_funding['Announced Date'].iloc[i-1]).days\n",
    "            time_diffs.append(time_diff)\n",
    "\n",
    "        # Calculate the average time to the next round (convert days to months)\n",
    "        avg_time_to_next_round = sum(time_diffs) / len(time_diffs) / 30\n",
    "\n",
    "    # Case 3: No funding rounds exist\n",
    "    else:\n",
    "        avg_time_to_next_round = None\n",
    "\n",
    "    # Handle invalid or missing data\n",
    "    if pd.isna(avg_time_to_next_round) or avg_time_to_next_round < -1:\n",
    "        avg_time_to_next_round = -1\n",
    "\n",
    "    return avg_time_to_next_round\n",
    "\n",
    "companies['Average Time To Next Round'] = companies.apply(\n",
    "    lambda row: calculate_avg_time_to_next_round(row['ID'], row['Founded Date'], funding), axis=1\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "602c99200acaebe9",
   "metadata": {},
   "source": [
    "### Feature 8: Average Funding Size\n",
    "The average size of funding rounds for a company (calculated as the total money raised divided by the number of funding rounds).\n",
    "\n",
    "Value:\n",
    "- 0: For companies with no funding data.\n",
    "- Positive values representing the average size of funding rounds."
   ]
  },
  {
   "cell_type": "code",
   "id": "fad3c613acd6a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:10.168858Z",
     "start_time": "2025-01-19T19:40:10.160011Z"
    }
   },
   "source": [
    "# Group the funding data frame by 'Company ID' to calculate summary statistics\n",
    "funding_summary = funding.groupby('Company ID').agg(\n",
    "    TotalMoneyRaised=('Money Raised', 'sum'),  # Sum of all money raised by the company\n",
    "    TotalRounds=('Money Raised', 'count')      # Count of funding rounds\n",
    ").reset_index()\n",
    "\n",
    "# Calculate the average funding size for each company\n",
    "funding_summary['Average Funding Size'] = funding_summary['TotalMoneyRaised'] / funding_summary['TotalRounds']\n",
    "\n",
    "# Merge the funding summary into the companies data frame\n",
    "# Match rows on 'ID' in companies and 'Company ID' in funding_summary\n",
    "companies = companies.merge(\n",
    "    funding_summary[['Company ID', 'Average Funding Size']],\n",
    "    left_on='ID',\n",
    "    right_on='Company ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values in 'Average Funding Size' with 0 for companies with no funding data\n",
    "companies['Average Funding Size'] = companies['Average Funding Size'].fillna(0)\n",
    "\n",
    "# Drop the redundant 'Company ID' column after the merge\n",
    "companies.drop(columns=['Company ID'], inplace=True)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "aafb7f4e7c118322",
   "metadata": {},
   "source": "## New Features: Companies <> Investors"
  },
  {
   "cell_type": "markdown",
   "id": "e06c97240687b560",
   "metadata": {},
   "source": [
    "### Feature 1-4: Average Number of Investments by Investors\n",
    "- Average Number of Investments by Investors\n",
    "- Average Number of Exits by Investors\n",
    "- Average Number of Lead Investments by Investors\n",
    "- Average Number of Portfolio Organizations by Investors"
   ]
  },
  {
   "cell_type": "code",
   "id": "ddab008378e0a978",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:10.215443Z",
     "start_time": "2025-01-19T19:40:10.179511Z"
    }
   },
   "source": [
    "# Explode the 'Investor Names' column in the funding data frame\n",
    "funding_exploded = funding.explode('Investor Names')\n",
    "\n",
    "# Remove leading and trailing whitespace from the 'Investor Names' column\n",
    "funding_exploded['Investor Names'] = funding_exploded['Investor Names'].str.strip()\n",
    "\n",
    "# Remove leading and trailing whitespace from the 'Organization/Person Name' column in the investors DataFrame\n",
    "investors['Organization/Person Name'] = investors['Organization/Person Name'].str.strip()\n",
    "\n",
    "# Merge the funding data with the investors data\n",
    "merged = funding_exploded.merge(\n",
    "    investors,\n",
    "    left_on='Investor Names',\n",
    "    right_on='Organization/Person Name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# List of columns containing numeric data to process\n",
    "columns_to_process = ['Number of Investments', 'Number of Exits', 'Number of Lead Investments', 'Number of Portfolio Organizations']\n",
    "\n",
    "# Convert the numeric columns to proper numeric data types, coercing invalid values to NaN\n",
    "for col in columns_to_process:\n",
    "    if col in merged.columns:\n",
    "        merged[col] = pd.to_numeric(merged[col], errors='coerce')\n",
    "\n",
    "# Identify investors not found in the investors DataFrame\n",
    "not_found_investors = merged[merged['Number of Investments'].isnull()]['Investor Names'].unique()\n",
    "\n",
    "# Print a message indicating the number of unmatched investors\n",
    "if len(not_found_investors) > 0:\n",
    "    print(f\"{len(not_found_investors)} investors could not be found.\")\n",
    "else:\n",
    "    print(\"All investors were successfully found.\")\n",
    "\n",
    "# Create a DataFrame of unmatched investors for reference or debugging\n",
    "not_found_investors_df = pd.DataFrame(not_found_investors, columns=['Investor Names'])\n",
    "\n",
    "# Remove the 'Company ID' column from companies if it exists to avoid duplication during the merge\n",
    "if 'Company ID' in companies.columns:\n",
    "    companies = companies.drop(columns=['Company ID'])\n",
    "\n",
    "# Calculate averages for each numeric column by 'Company ID' and merge with the companies DataFrame\n",
    "for col in columns_to_process:\n",
    "    col_average = merged.groupby('Company ID')[col].mean().reset_index()\n",
    "\n",
    "    # Merge\n",
    "    companies = companies.merge(\n",
    "        col_average,\n",
    "        left_on='ID',\n",
    "        right_on='Company ID',\n",
    "        how='left',\n",
    "        suffixes=('', '_drop')\n",
    "    )\n",
    "\n",
    "    # Replace NaN values with 0 for companies with no data for this column\n",
    "    companies[col] = companies[col].fillna(0)\n",
    "\n",
    "    # Rename the column to indicate it contains average data\n",
    "    companies = companies.rename(columns={col: f'Average {col} by Investors'})\n",
    "\n",
    "# Drop any temporary columns created during the merge (e.g., those ending with '_drop')\n",
    "companies = companies.drop(columns=[col for col in companies.columns if col.endswith('_drop')], errors='ignore')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3608 investors could not be found.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "806f2eccb150783f",
   "metadata": {},
   "source": [
    "### Feature 5: Origin Country of Investors\n",
    "Investor Country: Indicates whether the company has any investors from the specified country:\n",
    "- 1: At least one investor from the country is associated with the company.\n",
    "- 0: No investors from the country are associated with the company."
   ]
  },
  {
   "cell_type": "code",
   "id": "b5e5ae2c329a8b26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:10.246596Z",
     "start_time": "2025-01-19T19:40:10.228617Z"
    }
   },
   "source": [
    "# Explode the 'Investor Names' column in the funding data frame\n",
    "funding_exploded = funding.explode('Investor Names')\n",
    "\n",
    "# Remove leading and trailing whitespace from the 'Investor Names' and 'Organization/Person Name' column\n",
    "funding_exploded['Investor Names'] = funding_exploded['Investor Names'].str.strip()\n",
    "\n",
    "investors['Organization/Person Name'] = investors['Organization/Person Name'].str.strip()\n",
    "\n",
    "# Merge the funding data with the investors data to include the country information\n",
    "merged = funding_exploded.merge(\n",
    "    investors[['Organization/Person Name', 'Country']],\n",
    "    left_on='Investor Names',\n",
    "    right_on='Organization/Person Name',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Get the first 5 distinct countries from the investors dataset for encoding\n",
    "distinct_countries = investors['Country'].dropna().unique()[:5]\n",
    "\n",
    "# Perform one-hot encoding of the 'Country' column in the merged DataFrame\n",
    "country_encoded = pd.get_dummies(merged['Country'], prefix='Investor Country', dtype=int)\n",
    "\n",
    "# Aggregate the one-hot encoded columns by 'Company ID'\n",
    "# Use max() to ensure that if any investor from a given country is associated with a company, it gets a 1\n",
    "country_aggregated = country_encoded.groupby(merged['Company ID']).max()\n",
    "\n",
    "# Merge the aggregated country encoding data into the companies DataFrame\n",
    "companies = companies.merge(\n",
    "    country_aggregated,\n",
    "    left_on='ID',\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values for the encoded country columns with 0 (indicating no association with that country)\n",
    "for country in distinct_countries:\n",
    "    column_name = f'Investor Country: {country}'\n",
    "    if column_name in companies.columns:\n",
    "        companies[column_name] = companies[column_name].fillna(0)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "197c0c51",
   "metadata": {},
   "source": [
    "### Feature 6: Top Investor Participation\n",
    "Definition: A binary feature indicating whether a company's funding rounds included participation from top investors.\n",
    "\n",
    "Values:\n",
    "- 1: At least one top investor participated in the company's funding rounds.\n",
    "- 0: No top investors participated in the company's funding rounds."
   ]
  },
  {
   "cell_type": "code",
   "id": "bff198ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:10.723801Z",
     "start_time": "2025-01-19T19:40:10.258055Z"
    }
   },
   "source": [
    "# Identify top investors based on the 'Number of Exits' column\n",
    "# Top investors are defined as those with a number of exits greater than the mean\n",
    "top_investors = investors[investors['Number of Exits'] > investors['Number of Exits'].mean()]['Organization/Person Name']\n",
    "\n",
    "# Define a function to check if a company has participation from any top investor\n",
    "def has_top_investor(company_id, funding_df, top_investors):\n",
    "\n",
    "    # Filter the funding data for the specific company\n",
    "    company_funding = funding_df[funding_df['Company ID'] == company_id]\n",
    "\n",
    "    # If the company has no funding data, return 0 (no top investor participation)\n",
    "    if company_funding.empty:\n",
    "        return 0\n",
    "\n",
    "    # Explode the 'Investor Names' column to handle multiple investors per funding round\n",
    "    investors_list = company_funding['Investor Names'].explode()\n",
    "\n",
    "    # Check if any of the company's investors are in the top investors list\n",
    "    return 1 if any(investor in top_investors.values for investor in investors_list) else 0\n",
    "\n",
    "# Apply the function to each company in the companies data frame\n",
    "companies['Top Investor Participation'] = companies['ID'].apply(\n",
    "    lambda x: has_top_investor(x, funding, top_investors)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "7df5fd22cef165bd",
   "metadata": {},
   "source": [
    "## New Features: Companies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58313ce36f377e",
   "metadata": {},
   "source": [
    "### Feature 1: Category One Hot Encoding\n",
    "For each unique industry group in the Industry Groups column, a new binary feature is created:\n",
    "\n",
    "Industry_<Group>:\n",
    "- 1: The company is associated with the industry group <Group>.\n",
    "- 0: The company is not associated with the industry group <Group>."
   ]
  },
  {
   "cell_type": "code",
   "id": "b117d67700dbac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:10.749307Z",
     "start_time": "2025-01-19T19:40:10.736751Z"
    }
   },
   "source": [
    "# Explode the 'Industry Groups' column to create one row per industry group\n",
    "exploded = companies.explode('Industry Groups')\n",
    "\n",
    "# Clean the 'Industry Groups' column by stripping whitespace and converting text to lowercase\n",
    "exploded['Industry Groups'] = exploded['Industry Groups'].str.strip().str.lower()\n",
    "\n",
    "# Filter out rows where 'Industry Groups' is missing or empty\n",
    "exploded = exploded[exploded['Industry Groups'].notna() & (exploded['Industry Groups'] != '')]\n",
    "\n",
    "# Perform one-hot encoding on the 'Industry Groups' column\n",
    "one_hot_encoded = pd.get_dummies(exploded['Industry Groups'], prefix='Industry', dtype=int)\n",
    "\n",
    "# Aggregate the one-hot encoded columns by the original index of the 'companies' DataFrame\n",
    "# Use max() to ensure that if a company is associated with a specific industry group, it gets a 1\n",
    "one_hot_aggregated = one_hot_encoded.groupby(exploded.index).max()\n",
    "\n",
    "# Concatenate the aggregated one-hot encoded columns back to the original companies DataFrame\n",
    "companies = pd.concat([companies, one_hot_aggregated], axis=1)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## New Features: LinkedIn-Founder (Aggregation to Company Level)",
   "id": "65a94bb48c66942f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Feature 1-6: Average LinkedIn Followers and Connections\n",
    "\n",
    "- average_linkedin_followers_founders: Average number of LinkedIn followers of a company's founders.\n",
    "- average_linkedin_connections_founders: Average number of LinkedIn connections of a company's founders.\n",
    "- min_linkedin_followers_founders: Minimum number of LinkedIn followers among a company's founders.\n",
    "- max_linkedin_followers_founders: Maximum number of LinkedIn followers among a company's founders.\n",
    "- min_linkedin_connections_founders: Minimum number of LinkedIn connections among a company's founders.\n",
    "- max_linkedin_connections_founders: Maximum number of LinkedIn connections among a company's founders."
   ],
   "id": "6aca2aafba6a952b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:10.774412Z",
     "start_time": "2025-01-19T19:40:10.765187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_founder_metrics_to_companies(founders, companies):\n",
    "    # Group the founders data frame by 'Company ID' and calculate various aggregate metrics\n",
    "    founder_metrics = founders.groupby('Company ID').agg(\n",
    "        average_linkedin_followers_founders=('followers', 'mean'),\n",
    "\n",
    "        average_linkedin_connections_founders=('connections', 'mean'),\n",
    "\n",
    "        min_linkedin_followers_founders=('followers', 'min'),\n",
    "\n",
    "        max_linkedin_followers_founders=('followers', 'max'),\n",
    "\n",
    "        min_linkedin_connections_founders=('connections', 'min'),\n",
    "\n",
    "        max_linkedin_connections_founders=('connections', 'max')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Merge the aggregated founder metrics into the companies data frame\n",
    "    companies = companies.merge(founder_metrics, left_on='ID', right_on='Company ID', how='left')\n",
    "\n",
    "    # Remove redundant or duplicate 'Company ID' columns from the merged DataFrame\n",
    "    for col in ['Company ID', 'Company ID_y']:\n",
    "        if col in companies.columns:\n",
    "            companies.drop(columns=[col], inplace=True)\n",
    "\n",
    "    # Return the updated companies DataFrame\n",
    "    return companies\n",
    "\n",
    "# Apply the function to add founder metrics to the companies data frame\n",
    "companies = add_founder_metrics_to_companies(founders, companies)"
   ],
   "id": "a3ed95f296e207d2",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature 7-9: Highest Education\n",
    "\n",
    "- Highest Education_Doctor/PhD: The number of founders in a company with a Doctorate/PhD degree.\n",
    "- Highest Education_Master: The number of founders in a company with a Master's degree.\n",
    "- Highest Education_Bachelor: The number of founders in a company with a Bachelor's degree."
   ],
   "id": "e8c87228a84b16f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:10.851155Z",
     "start_time": "2025-01-19T19:40:10.796289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def categorize_highest_education(founders):\n",
    "    # Define a mapping of degree keywords to education levels\n",
    "    education_mapping = {\n",
    "        \"Doctor/PhD\": [\n",
    "            \"phd\", \"doctor\", \"doctoral\", \"dr.\", \"d.phil\", \"doctorate\", \"dsc\",\n",
    "            \"dr.phil\", \"doctor of science\", \"dr.eng\", \"ph.d\", \"ed.d\", \"sc.d\",\n",
    "            \"eng.d\", \"dr.med\", \"med.d\", \"doctor of medicine\", \"doctor of philosophy\",\n",
    "            \"d.ed\", \"jd\", \"juris doctor\", \"doctor juris\", \"law doctorate\", \"d.v.m\",\n",
    "            \"doctor of veterinary\", \"md\", \"m.d.\", \"doctor of law\", \"doctor of arts\",\n",
    "            \"doctor in\", \"doctoral studies\", \"d.lit\", \"d.m.a\", \"d.clin.psych\",\n",
    "            \"doctor of clinical psychology\", \"d.jur\", \"d.theol\", \"d.b.a\",\n",
    "            \"doctor of business administration\", \"d.eng.sc\", \"d.arch\", \"d.d.s\",\n",
    "            \"doctor of dental surgery\", \"d.v.sc\", \"d.med.sc\", \"d.p.h\",\n",
    "            \"d.sc.tech\", \"doctor of public health\", \"d.health.sci\", \"d.n.p\",\n",
    "            \"doctor of nursing practice\", \"doctor of social work\", \"doctor of theology\",\n",
    "            \"d.comm\", \"doctor of communication\", \"d.env.sc\", \"doctor of environmental science\"\n",
    "        ],\n",
    "        \"Master\": [\n",
    "            \"master\", \"m.sc\", \"msc\", \"mba\", \"m.tech\", \"ma\", \"m.eng\", \"m.ed\",\n",
    "            \"ms\", \"m.phil\", \"mfa\", \"m.econ\", \"mfin\", \"master of science\",\n",
    "            \"master of arts\", \"master of business\", \"master's degree\",\n",
    "            \"m.des\", \"m.com\", \"m.div\", \"m.theol\", \"mres\", \"m.arch\", \"m.acc\",\n",
    "            \"master of engineering\", \"master of finance\", \"master of commerce\",\n",
    "            \"master of education\", \"master of philosophy\", \"master of public health\",\n",
    "            \"mph\", \"m.pp\", \"m.ir\", \"mib\", \"m.int.business\", \"m.litt\", \"mchem\",\n",
    "            \"diplom\", \"diploma\", \"diplom-ing\", \"diploma in engineering\",\n",
    "            \"dipl.-ing\", \"dipl.-wirtschaftsingenieur\", \"dipl.-kfm\", \"dipl.-phys\",\n",
    "            \"dipl.-math\", \"diplomkaufmann\", \"diplomingenieur\", \"diplomat\",\n",
    "            \"m.comm\", \"m.a.ed\", \"m.sc.ed\", \"m.p.a\", \"m.h.a\", \"m.i.s\", \"m.c.s\",\n",
    "            \"master of computer science\", \"master of information systems\",\n",
    "            \"m.sc.tech\", \"m.plan\", \"master of planning\", \"mcm\", \"master of communication\",\n",
    "            \"mhl\", \"master of human resources\", \"m.intl.rel\", \"master of international relations\",\n",
    "            \"m.i.t\", \"m.arch.sc\", \"master of architecture\", \"m.journ\", \"m.fish.sci\",\n",
    "            \"master of fisheries science\", \"m.r.s\", \"master of rural studies\",\n",
    "            \"m.theo\", \"m.e.e\", \"master of electrical engineering\", \"m.med.sc\",\n",
    "            \"m.env.sc\", \"master of environmental science\", \"m.agri\", \"master of agriculture\",\n",
    "            \"m.p.h.a\", \"master of public health administration\", \"m.sc.math\"\n",
    "        ],\n",
    "        \"Bachelor\": [\n",
    "            \"bachelor\", \"b.sc\", \"bsc\", \"b.tech\", \"ba\", \"b.eng\", \"b.ed\",\n",
    "            \"bs\", \"b.arch\", \"bcom\", \"bba\", \"bfa\", \"bpharm\", \"b.econ\",\n",
    "            \"bachelor's degree\", \"undergraduate\", \"bcom\", \"bdes\", \"bca\",\n",
    "            \"bacc\", \"bachelor of science\", \"bachelor of arts\", \"bachelor of technology\",\n",
    "            \"bachelor of engineering\", \"bachelor of education\", \"bachelor of commerce\",\n",
    "            \"bachelor of fine arts\", \"bachelor of pharmacy\", \"bachelor of law\",\n",
    "            \"bachelor of economics\", \"llb\", \"bachelor of computer applications\",\n",
    "            \"b.litt\", \"b.a.e\", \"b.sc.eng\", \"b.plan\", \"b.comm\", \"b.h.sc\",\n",
    "            \"b.i.t\", \"b.math\", \"b.stat\", \"b.mus\", \"b.of.design\", \"bcs\",\n",
    "            \"bachelor of computing science\", \"b.eng.tech\", \"b.a.sc\", \"b.app.sci\",\n",
    "            \"b.e\", \"b.journ\", \"b.a.hons\", \"b.sc.hons\", \"b.nurs\", \"b.sc.n\",\n",
    "            \"b.soc.sc\", \"b.soc.work\", \"bachelor of social work\", \"b.v.sc\",\n",
    "            \"bachelor of veterinary science\", \"b.med.sc\", \"b.biochem\",\n",
    "            \"bachelor of biochemistry\", \"b.a.s\", \"b.env.sc\", \"bachelor of environmental science\",\n",
    "            \"b.med\", \"bachelor of medicine\", \"b.optom\", \"bachelor of optometry\",\n",
    "            \"b.psych\", \"bachelor of psychology\", \"b.public.health\", \"b.p.t\",\n",
    "            \"bachelor of physical therapy\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Define a priority mapping for education levels\n",
    "    education_priority = {\"Doctor/PhD\": 3, \"Master\": 2, \"Bachelor\": 1}\n",
    "\n",
    "    def get_highest_education(degree):\n",
    "        degree_lower = str(degree).lower()\n",
    "        for level, keywords in education_mapping.items():\n",
    "            if any(keyword in degree_lower for keyword in keywords):\n",
    "                return level\n",
    "        return None\n",
    "\n",
    "    # Categorize the level of each degree for degree_1 and degree_2\n",
    "    founders['degree_1_level'] = founders['degree_1'].apply(get_highest_education)\n",
    "    founders['degree_2_level'] = founders['degree_2'].apply(get_highest_education)\n",
    "\n",
    "    # Map education levels to priorities for comparison\n",
    "    founders['degree_1_priority'] = founders['degree_1_level'].map(education_priority).fillna(0)\n",
    "    founders['degree_2_priority'] = founders['degree_2_level'].map(education_priority).fillna(0)\n",
    "\n",
    "    # Determine the highest education level between degree_1 and degree_2\n",
    "    founders['Highest Education'] = founders.apply(\n",
    "        lambda row: row['degree_1_level'] if row['degree_1_priority'] >= row['degree_2_priority'] else row['degree_2_level'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return founders\n",
    "\n",
    "def add_highest_education_one_hot_to_companies(founders, companies):\n",
    "    # Categorize the highest education level for each founder\n",
    "    founders = categorize_highest_education(founders)\n",
    "\n",
    "    # Perform one-hot encoding on the 'Highest Education' column\n",
    "    one_hot_encoded = pd.get_dummies(founders['Highest Education'], prefix='Highest Education')\n",
    "\n",
    "    # Add the one-hot encoded columns back to the founders data frame\n",
    "    founders = pd.concat([founders, one_hot_encoded], axis=1)\n",
    "\n",
    "    # Aggregate the one-hot encoded data by Company ID\n",
    "    aggregated_one_hot = founders.groupby('Company ID')[one_hot_encoded.columns].sum().reset_index()\n",
    "\n",
    "    # Merge the aggregated one-hot data into the companies DataFrame\n",
    "    companies = companies.merge(aggregated_one_hot, left_on='ID', right_on='Company ID', how='left')\n",
    "\n",
    "    # Fill missing values with 0 for companies with no associated founders\n",
    "    companies.fillna(0, inplace=True)\n",
    "\n",
    "    # Drop the redundant 'Company ID' column from the merged DataFrame\n",
    "    companies.drop(columns=['Company ID'], inplace=True, errors='ignore')\n",
    "    return companies\n",
    "\n",
    "# Apply the function\n",
    "companies = add_highest_education_one_hot_to_companies(founders, companies)"
   ],
   "id": "2e00bb1f42d901c2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n8/ynbdx9r10lv6l8yh1m_hmbsh0000gn/T/ipykernel_3935/3398100639.py:103: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  companies.fillna(0, inplace=True)\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:10.914629Z",
     "start_time": "2025-01-19T19:40:10.869680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_recognition_rate(founders):\n",
    "    # Filter founders who have at least one degree\n",
    "    total_with_degrees = founders[\n",
    "        founders['degree_1'].notna() | founders['degree_2'].notna()\n",
    "        ]\n",
    "\n",
    "    # Count the number of degrees that are successfully recognized/mapped to education levels\n",
    "    recognized_degrees = total_with_degrees['Highest Education'].notna().sum()\n",
    "\n",
    "    # Count the total number of entries with at least one degree\n",
    "    total_with_degrees_count = len(total_with_degrees)\n",
    "\n",
    "    # Calculate the recognition rate as the proportion of recognized degrees\n",
    "    recognition_rate = recognized_degrees / total_with_degrees_count if total_with_degrees_count > 0 else 0\n",
    "\n",
    "    return recognition_rate, total_with_degrees_count, recognized_degrees\n",
    "\n",
    "founders = categorize_highest_education(founders)\n",
    "\n",
    "# Calculate the recognition rate and related statistics\n",
    "recognition_rate, total_with_degrees, recognized_count = calculate_recognition_rate(founders)\n",
    "\n",
    "print(f\"Recognition Rate: {recognition_rate:.2%}\")\n",
    "print(f\"Total Entries with Degrees: {total_with_degrees}\")\n",
    "print(f\"Recognized Degrees: {recognized_count}\")\n"
   ],
   "id": "7aaebb231748676b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognition Rate: 91.04%\n",
      "Total Entries with Degrees: 1663\n",
      "Recognized Degrees: 1514\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Feature 10: International Team\n",
    "A binary feature indicating whether the company has at least one founder from a country other than Germany.\n",
    "\n",
    "Values:\n",
    "- 1: The company has at least one international founder.\n",
    "- 0: All founders are from Germany, or no founder data is available for the company."
   ],
   "id": "777745af9d7b727f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:40:10.938820Z",
     "start_time": "2025-01-19T19:40:10.931664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_international_team_to_companies(founders, companies):\n",
    "    # Create a binary column in founders to indicate if a founder is international\n",
    "    founders['is_international'] = founders['country_code'].apply(\n",
    "        lambda x: 0 if x == 'DEU' or x is None else 1\n",
    "    )\n",
    "\n",
    "    # Group by 'Company ID' to determine if any founder in the company is international\n",
    "    # Use max() to check if at least one founder is international\n",
    "    international_team = founders.groupby('Company ID')['is_international'].max().reset_index()\n",
    "\n",
    "    # Rename the column to 'International Team' for clarity\n",
    "    international_team.rename(columns={'is_international': 'International Team'}, inplace=True)\n",
    "\n",
    "    # Merge the 'International Team' data into the companies DataFrame\n",
    "    companies = companies.merge(international_team, left_on='ID', right_on='Company ID', how='left')\n",
    "\n",
    "    # Fill missing values with 0 for companies with no founders\n",
    "    companies['International Team'].fillna(0, inplace=True)\n",
    "\n",
    "    # Ensure the 'International Team' column is an integer type\n",
    "    companies['International Team'] = companies['International Team'].astype(int)\n",
    "\n",
    "    # Drop the redundant 'Company ID' column from the merged data frame if it exists\n",
    "    if 'Company ID' in companies.columns:\n",
    "        companies.drop(columns=['Company ID'], inplace=True)\n",
    "\n",
    "    return companies\n",
    "\n",
    "# Apply the function to add the 'International Team' feature to the companies data frame\n",
    "companies = add_international_team_to_companies(founders, companies)"
   ],
   "id": "cbcba255b9522be8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n8/ynbdx9r10lv6l8yh1m_hmbsh0000gn/T/ipykernel_3935/2678057080.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  companies['International Team'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Feature 11: Top University\n",
    "The proportion of a company's founders who have a degree from a top university."
   ],
   "id": "ad380a583b7237fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:45:54.180660Z",
     "start_time": "2025-01-19T19:45:53.709057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# New import because rapidfuzz should be used\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Load university ranking data\n",
    "ranking = pd.read_csv('../../Datasets/Universities/UniversityRanking.csv')\n",
    "\n",
    "# Convert the 'rank display' column to numeric, coercing errors to NaN\n",
    "ranking['rank display'] = pd.to_numeric(ranking['rank display'], errors='coerce')\n",
    "\n",
    "# Filter for the top 100 universities based on ranking\n",
    "top100 = ranking[ranking['rank display'] <= 100]\n",
    "\n",
    "# Extract a list of the top 100 university names\n",
    "top_universities = top100['institution'].dropna().unique().tolist()\n",
    "\n",
    "def get_top_university_match(uni, top_universities_list, threshold=90):\n",
    "    if pd.isna(uni) or not uni.strip():\n",
    "        return None, 0\n",
    "    # Use RapidFuzz to find the best match in the list of top universities\n",
    "    match = process.extractOne(uni, top_universities_list, scorer=fuzz.token_set_ratio)\n",
    "    if match and match[1] >= threshold:\n",
    "        return match[0], match[1]\n",
    "    return None, 0\n",
    "\n",
    "# Initialize columns for top university matching and scores\n",
    "founders['degree_1_top_match'] = None\n",
    "founders['degree_1_top_score'] = 0\n",
    "founders['degree_2_top_match'] = None\n",
    "founders['degree_2_top_score'] = 0\n",
    "\n",
    "# Iterate through each founder and find matches for their degree universities\n",
    "for idx, row in founders.iterrows():\n",
    "    uni1 = row.get('degree_1_university', '')\n",
    "    uni2 = row.get('degree_2_university', '')\n",
    "\n",
    "    # Find the best match for each degree\n",
    "    match1, score1 = get_top_university_match(uni1, top_universities)\n",
    "    match2, score2 = get_top_university_match(uni2, top_universities)\n",
    "\n",
    "    # Store the matches and scores in the DataFrame\n",
    "    founders.at[idx, 'degree_1_top_match'] = match1\n",
    "    founders.at[idx, 'degree_1_top_score'] = score1\n",
    "    founders.at[idx, 'degree_2_top_match'] = match2\n",
    "    founders.at[idx, 'degree_2_top_score'] = score2\n",
    "\n",
    "print(founders[['degree_1_university', 'degree_1_top_match', 'degree_1_top_score',\n",
    "                'degree_2_university', 'degree_2_top_match', 'degree_2_top_score']].head())\n",
    "\n",
    "def check_top_university(universities, top_universities_list, threshold=90):\n",
    "    for uni in universities:\n",
    "        if pd.isna(uni) or not uni.strip():\n",
    "            continue\n",
    "        # Use RapidFuzz to find the best match in the list of top universities\n",
    "        match = process.extractOne(uni, top_universities_list, scorer=fuzz.token_set_ratio)\n",
    "        if match and match[1] >= threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Add a binary column to indicate if a founder has a degree from a top university\n",
    "founders['founder_top_uni'] = founders.apply(\n",
    "    lambda row: check_top_university(\n",
    "        [row.get('degree_1_university', ''), row.get('degree_2_university', '')],\n",
    "        top_universities\n",
    "    ),\n",
    "    axis=1\n",
    ").astype(int)\n",
    "\n",
    "# Group by 'Company ID' to calculate the proportion of founders from top universities\n",
    "company_top_uni = founders.groupby('Company ID')['founder_top_uni'].mean().reset_index()\n",
    "\n",
    "# Merge the top university data into the companies data frame\n",
    "companies = companies.merge(company_top_uni, left_on='ID', right_on='Company ID', how='left')\n",
    "\n",
    "# Fill missing values with 0 and rename the column for clarity\n",
    "companies['Top University'] = companies['founder_top_uni'].fillna(0)\n",
    "\n",
    "# Drop redundant columns after merging\n",
    "companies.drop(['Company ID', 'founder_top_uni'], axis=1, inplace=True)"
   ],
   "id": "9477001fddffa81b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n8/ynbdx9r10lv6l8yh1m_hmbsh0000gn/T/ipykernel_3935/3171906205.py:42: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '93.87755102040816' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  founders.at[idx, 'degree_1_top_score'] = score1\n",
      "/var/folders/n8/ynbdx9r10lv6l8yh1m_hmbsh0000gn/T/ipykernel_3935/3171906205.py:44: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '95.65217391304348' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  founders.at[idx, 'degree_2_top_score'] = score2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              degree_1_university degree_1_top_match  degree_1_top_score  \\\n",
      "0            ESCP Business School               None                 0.0   \n",
      "2                             NaN               None                 0.0   \n",
      "3  Technische Universität München               None                 0.0   \n",
      "4                             NaN               None                 0.0   \n",
      "5                             NaN               None                 0.0   \n",
      "\n",
      "                        degree_2_university               degree_2_top_match  \\\n",
      "0  EBS Universität für Wirtschaft und Recht                             None   \n",
      "2                                       NaN                             None   \n",
      "3           Georgia Institute of Technology  Georgia Institute of Technology   \n",
      "4                                       NaN                             None   \n",
      "5                                       NaN                             None   \n",
      "\n",
      "   degree_2_top_score  \n",
      "0                 0.0  \n",
      "2                 0.0  \n",
      "3               100.0  \n",
      "4                 0.0  \n",
      "5                 0.0  \n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Feature 12: Studies Abroad\n",
    "The proportion of a company's founders who have a degree from a foreign university (outside Germany, Switzerland, and Austria).\n",
    "\n",
    "Values:\n",
    "- 1: All founders studied abroad.\n",
    "- Between 0 and 1: Some but not all founders studied abroad.\n",
    "- 0: No founders studied abroad, or no founder data is available."
   ],
   "id": "b365cc02066dbe41"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:45:59.481296Z",
     "start_time": "2025-01-19T19:45:57.408798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter universities outside Germany (DE), Switzerland (CH), and Austria (AT)\n",
    "foreign_universities = ranking[~ranking['location code'].isin(['DE', 'CH', 'AT'])]\n",
    "\n",
    "# Extract the list of foreign university names\n",
    "foreign_universities = foreign_universities['institution'].dropna().unique().tolist()\n",
    "\n",
    "def check_foreign_university(universities, foreign_universities_list, threshold=90):\n",
    "    for uni in universities:\n",
    "        if pd.isna(uni) or not uni.strip():\n",
    "            continue\n",
    "        # Use RapidFuzz to find the best match in the list of foreign universities\n",
    "        match = process.extractOne(uni, foreign_universities_list, scorer=fuzz.token_set_ratio)\n",
    "        if match and match[1] >= threshold:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Add a binary column indicating whether a founder studied abroad\n",
    "founders['founder_studies_abroad'] = founders.apply(\n",
    "    lambda row: check_foreign_university(\n",
    "        [row.get('degree_1_university', ''), row.get('degree_2_university', '')],  # Universities from degrees\n",
    "        foreign_universities\n",
    "    ),\n",
    "    axis=1\n",
    ").astype(int)\n",
    "\n",
    "# Group by 'Company ID' to calculate the proportion of founders who studied abroad\n",
    "company_abroad = founders.groupby('Company ID')['founder_studies_abroad'].mean().reset_index()\n",
    "\n",
    "# Merge the proportion of founders who studied abroad into the companies data frame\n",
    "companies = companies.merge(company_abroad, left_on='ID', right_on='Company ID', how='left')\n",
    "\n",
    "# Fill missing values with 0 and rename the column for clarity\n",
    "companies['Studies Abroad Founder'] = companies['founder_studies_abroad'].fillna(0)\n",
    "\n",
    "# Drop redundant columns after merging\n",
    "companies.drop(['Company ID', 'founder_studies_abroad'], axis=1, inplace=True)\n"
   ],
   "id": "9a24fb9c74a32f80",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## New Features: Companies <> LinkedIn Founder Information",
   "id": "5c46205047b4c74e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:46:00.875536Z",
     "start_time": "2025-01-19T19:46:00.836596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data set with additional information about founder\n",
    "ln_filepath= '../Social Media Webscraping/Results/LinkedIn/Founders/founders_linkedin.csv'\n",
    "\n",
    "ln_details = pd.read_csv(ln_filepath)"
   ],
   "id": "f94a4e7a584b64aa",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature 1-3: First Time Founder\n",
    "- firsttime_founder_ratio: The proportion of founders who are first-time founders.\n",
    "- all_firsttime_founders: Indicator of whether all founders are first-time founders.\n",
    "- any_firsttime_founder: Indicator of whether at least one founder is a first-time founder."
   ],
   "id": "8f5f9a8f3d0af1e9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:47:40.875655Z",
     "start_time": "2025-01-19T19:46:03.498292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fill NaN values in ln_details with empty strings for consistent string processing\n",
    "ln_details = ln_details.fillna(\"\")\n",
    "\n",
    "# Merge LinkedIn details (ln_details) with founders using the LinkedIn URL as the key\n",
    "merged = ln_details.merge(founders, left_on=\"url\", right_on=\"linkedin_url\", how=\"left\")\n",
    "\n",
    "# Define a function to filter and extract job titles relevant to the founder's organization\n",
    "def filter_job_titles(row):\n",
    "    organization = row[\"Organization Name\"]\n",
    "    job_titles = []\n",
    "    match_found = False\n",
    "\n",
    "    # Loop through up to 10 job history records\n",
    "    for i in range(1, 11):\n",
    "        company_col = f\"job_company_{i}\"\n",
    "        title_col = f\"job_title_{i}\"\n",
    "\n",
    "        if company_col in row and title_col in row:\n",
    "            company = row[company_col]\n",
    "            if not match_found and fuzz.partial_ratio(organization.lower(), company.lower()) > 80:\n",
    "\n",
    "                match_found = True\n",
    "                continue\n",
    "            if match_found and row[title_col]:\n",
    "                job_titles.append(row[title_col])\n",
    "\n",
    "    return \" \".join(job_titles)\n",
    "\n",
    "# Apply the filter_job_titles function to extract relevant job titles\n",
    "merged[\"filtered_job_titles\"] = merged.apply(filter_job_titles, axis=1)\n",
    "\n",
    "# Load the zero-shot classification model for identifying founder roles\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "def is_founder(row):\n",
    "    job_titles = row[\"filtered_job_titles\"]\n",
    "    if not job_titles.strip():\n",
    "        return 1\n",
    "\n",
    "    # Classify job titles as 'founder' or 'not a founder'\n",
    "    result = classifier(\n",
    "        job_titles,\n",
    "        candidate_labels=[\"founder\", \"not a founder\"],\n",
    "        hypothesis_template=\"This person is a {}.\"\n",
    "    )\n",
    "\n",
    "    # Return classification result\n",
    "    return 0 if result[\"labels\"][0] == \"founder\" else 1\n",
    "\n",
    "# Apply the is_founder function to classify each person as a first-time founder\n",
    "merged[\"is_firsttime_founder\"] = merged.apply(is_founder, axis=1)\n",
    "\n",
    "# Validate that the is_firsttime_founder column was successfully created\n",
    "if \"is_firsttime_founder\" not in merged.columns:\n",
    "    raise ValueError(\"is_firsttime_founder column was not created correctly in merged.\")\n",
    "\n",
    "# Display the first few rows of LinkedIn URL and first-time founder classification\n",
    "print(merged[[\"linkedin_url\", \"is_firsttime_founder\"]].head())\n",
    "\n",
    "# Merge the first-time founder classification back into the founders data frame\n",
    "founders = founders.merge(\n",
    "    merged[[\"linkedin_url\", \"is_firsttime_founder\"]],\n",
    "    left_on=\"linkedin_url\",\n",
    "    right_on=\"linkedin_url\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Validate that the is_firsttime_founder column was added to the founders data frame\n",
    "if \"is_firsttime_founder\" not in founders.columns:\n",
    "    raise ValueError(\"is_firsttime_founder column was not added to founders.\")\n",
    "\n",
    "# Calculate first-time founder statistics at the company level\n",
    "company_firsttime_stats = founders.groupby('Company ID')['is_firsttime_founder'].agg(\n",
    "    firsttime_founder_ratio='mean',\n",
    "    all_firsttime_founders=lambda x: int(x.mean() == 1),\n",
    "    any_firsttime_founder=lambda x: int(x.mean() > 0)\n",
    ").reset_index()\n",
    "\n",
    "# Ensure company and statistics data frame IDs are strings for merging\n",
    "companies['ID'] = companies['ID'].astype(str)\n",
    "company_firsttime_stats['Company ID'] = company_firsttime_stats['Company ID'].astype(str)\n",
    "\n",
    "# Merge first-time founder statistics into the companies data frame\n",
    "companies = companies.merge(company_firsttime_stats, left_on='ID', right_on='Company ID', how='left')\n",
    "\n",
    "# Fill missing values for companies with no founder data\n",
    "companies['firsttime_founder_ratio'] = companies['firsttime_founder_ratio'].fillna(0)\n",
    "companies['all_firsttime_founders'] = companies['all_firsttime_founders'].fillna(0)\n",
    "companies['any_firsttime_founder'] = companies['any_firsttime_founder'].fillna(0)\n",
    "\n",
    "companies.drop(['Company ID'], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns for better readability\n",
    "companies.rename(columns={\n",
    "    'firsttime_founder_ratio': 'Firsttime Founder Ratio',\n",
    "    'all_firsttime_founders': 'All Firsttime Founders',\n",
    "    'any_firsttime_founder': 'Any Firsttime Founder'\n",
    "}, inplace=True)"
   ],
   "id": "58975240076691cd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        linkedin_url  is_firsttime_founder\n",
      "0  https://www.linkedin.com/in/johannes-stoffel-2...                     0\n",
      "1              https://www.linkedin.com/in/zkaramat/                     0\n",
      "2  https://www.linkedin.com/in/alexandre-gu%C3%A9...                     0\n",
      "3                 https://www.linkedin.com/in/mituca                     1\n",
      "4           https://www.linkedin.com/in/antoine-jeol                     0\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature 4-6: Researcher",
   "id": "6581948acfbeca5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Researcher Ratio:Proportion of a company's founders classified as researchers.\n",
    "- All Researchers: Binary indicator (1 or 0) denoting whether all founders in a company are researchers.\n",
    "- Any Researcher: Binary indicator (1 or 0) denoting whether at least one founder in a company is a researcher."
   ],
   "id": "f9769e4080561378"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:54:13.146726Z",
     "start_time": "2025-01-19T19:52:46.017169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fill missing values in LinkedIn details with empty strings for consistent processing\n",
    "ln_details = ln_details.fillna(\"\")\n",
    "\n",
    "# Merge LinkedIn details (ln_details) with founders data using the LinkedIn URL as the key\n",
    "merged = ln_details.merge(founders, left_on=\"url\", right_on=\"linkedin_url\", how=\"left\")\n",
    "\n",
    "def filter_job_titles(row):\n",
    "    organization = row[\"Organization Name\"]  # The founder's organization\n",
    "    job_titles = []  # List to store relevant job titles\n",
    "    match_found = False  # Flag to identify if the organization is matched\n",
    "\n",
    "    # Iterate over up to 10 job history entries\n",
    "    for i in range(1, 11):\n",
    "        company_col = f\"job_company_{i}\"\n",
    "        title_col = f\"job_title_{i}\"\n",
    "\n",
    "        # Ensure the necessary columns exist\n",
    "        if company_col in row and title_col in row:\n",
    "            company = row[company_col]\n",
    "            # Match the founder's organization with the job history company using string similarity\n",
    "            if not match_found and fuzz.partial_ratio(organization.lower(), company.lower()) > 80:\n",
    "                match_found = True\n",
    "                continue\n",
    "            # Collect job titles after the organization is matched\n",
    "            if match_found and row[title_col]:\n",
    "                job_titles.append(row[title_col])\n",
    "\n",
    "    return \" \".join(job_titles)\n",
    "\n",
    "# Apply the filter_job_titles function to extract job titles for each row\n",
    "merged[\"filtered_job_titles\"] = merged.apply(filter_job_titles, axis=1)\n",
    "\n",
    "# Load a zero-shot classification model for identifying researcher roles\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "def is_researcher(row):\n",
    "    job_titles = row[\"filtered_job_titles\"]\n",
    "    if not job_titles.strip():\n",
    "        return 0\n",
    "\n",
    "    result = classifier(\n",
    "        job_titles,\n",
    "        candidate_labels=[\"researcher\", \"not a researcher\"],\n",
    "        hypothesis_template=\"This person is a {}.\"\n",
    "    )\n",
    "\n",
    "    return 1 if result[\"labels\"][0] == \"researcher\" else 0\n",
    "\n",
    "# Apply the is_researcher function to classify each person as a researcher\n",
    "merged[\"was_researcher\"] = merged.apply(is_researcher, axis=1)\n",
    "\n",
    "# Merge the researcher classification results back into the founders DataFrame\n",
    "founders = founders.merge(\n",
    "    merged[[\"linkedin_url\", \"was_researcher\"]],\n",
    "    left_on=\"linkedin_url\",\n",
    "    right_on=\"linkedin_url\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Calculate researcher-related statistics at the company level\n",
    "company_researcher_stats = founders.groupby('Company ID')['was_researcher'].agg(\n",
    "    researcher_ratio='mean',\n",
    "    all_researchers=lambda x: int(x.mean() == 1),\n",
    "    any_researcher=lambda x: int(x.mean() > 0)\n",
    ").reset_index()\n",
    "\n",
    "# Ensure company IDs are strings for merging consistency\n",
    "companies['ID'] = companies['ID'].astype(str)\n",
    "company_researcher_stats['Company ID'] = company_researcher_stats['Company ID'].astype(str)\n",
    "\n",
    "# Merge researcher statistics into the companies DataFrame\n",
    "companies = companies.merge(company_researcher_stats, left_on='ID', right_on='Company ID', how='left')\n",
    "\n",
    "# Fill missing values for companies with no founder data\n",
    "companies['researcher_ratio'] = companies['researcher_ratio'].fillna(0)\n",
    "companies['all_researchers'] = companies['all_researchers'].fillna(0)\n",
    "companies['any_researcher'] = companies['any_researcher'].fillna(0)\n",
    "\n",
    "# Drop redundant columns after merging\n",
    "companies.drop(['Company ID'], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns for better readability\n",
    "companies.rename(columns={\n",
    "    'researcher_ratio': 'Researcher Ratio',\n",
    "    'all_researchers': 'All Researchers',\n",
    "    'any_researcher': 'Any Researcher'\n",
    "}, inplace=True)\n"
   ],
   "id": "9c164d37bd177c2b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature 7-9: Senior Roles\n",
    "- Executive Ratio: Definition: Proportion of a company's founders who held executive roles before joining the company.\n",
    "- All Executives: Definition: Binary indicator (1 or 0) denoting whether all founders in a company held executive roles.\n",
    "- Any Executive: Binary indicator (1 or 0) denoting whether at least one founder in a company held an executive role."
   ],
   "id": "6bf4f1f621ec5540"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:55:34.683966Z",
     "start_time": "2025-01-19T19:54:29.765081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Fill missing values in LinkedIn details data frame with empty strings for consistency\n",
    "ln_details = ln_details.fillna(\"\")\n",
    "\n",
    "# Merge LinkedIn details with founders data frame on the LinkedIn URL\n",
    "merged = ln_details.merge(founders, left_on=\"url\", right_on=\"linkedin_url\", how=\"left\")\n",
    "\n",
    "def filter_pre_foundation_jobs(row):\n",
    "    organization = row[\"Organization Name\"]\n",
    "    job_titles = []\n",
    "\n",
    "    for i in range(1, 11):  # Loop through up to 10 job history records\n",
    "        company_col = f\"job_company_{i}\"\n",
    "        title_col = f\"job_title_{i}\"\n",
    "\n",
    "        if company_col in row and title_col in row:\n",
    "            company = row[company_col]\n",
    "            # Stop collecting job titles once the founder's organization is found\n",
    "            if fuzz.partial_ratio(organization.lower(), company.lower()) > 80:\n",
    "                break\n",
    "            # Add job title to the list if available\n",
    "            if row[title_col]:\n",
    "                job_titles.append(row[title_col])\n",
    "\n",
    "    return \" \".join(job_titles)\n",
    "\n",
    "# Apply the filter_pre_foundation_jobs function to extract relevant job titles\n",
    "merged[\"filtered_job_titles\"] = merged.apply(filter_pre_foundation_jobs, axis=1)\n",
    "\n",
    "# Load the zero-shot classification model for identifying executive roles\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "def is_executive(row):\n",
    "    job_titles = row[\"filtered_job_titles\"]\n",
    "    if not job_titles.strip():\n",
    "        return 0\n",
    "\n",
    "    # Classify job titles as 'executive' or 'not an executive'\n",
    "    result = classifier(\n",
    "        job_titles,\n",
    "        candidate_labels=[\"executive\", \"not an executive\"],\n",
    "        hypothesis_template=\"This person is a {}.\"\n",
    "    )\n",
    "\n",
    "    return 1 if result[\"labels\"][0] == \"executive\" else 0  # Return classification result\n",
    "\n",
    "# Apply the is_executive function to classify each person based on their job titles\n",
    "merged[\"was_executive\"] = merged.apply(is_executive, axis=1)\n",
    "\n",
    "# Validate that the was_executive column was successfully created\n",
    "if \"was_executive\" not in merged.columns:\n",
    "    raise ValueError(\"Column 'was_executive' was not created in merged.\")\n",
    "\n",
    "# Merge the executive classification results back into the founders data frame\n",
    "founders = founders.merge(\n",
    "    merged[[\"linkedin_url\", \"was_executive\"]],\n",
    "    left_on=\"linkedin_url\",\n",
    "    right_on=\"linkedin_url\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Validate that the was_executive column was added to the founders data frame\n",
    "if \"was_executive\" not in founders.columns:\n",
    "    raise ValueError(\"Column 'was_executive' was not added to founders.\")\n",
    "\n",
    "# Calculate executive statistics at the company level\n",
    "company_executive_stats = founders.groupby('Company ID')['was_executive'].agg(\n",
    "    executive_ratio='mean',\n",
    "    all_executives=lambda x: int(x.mean() == 1),\n",
    "    any_executive=lambda x: int(x.mean() > 0)\n",
    ").reset_index()\n",
    "\n",
    "# Ensure company IDs are strings for merging consistency\n",
    "companies['ID'] = companies['ID'].astype(str)\n",
    "company_executive_stats['Company ID'] = company_executive_stats['Company ID'].astype(str)\n",
    "\n",
    "# Merge executive statistics into the companies data frame\n",
    "companies = companies.merge(company_executive_stats, left_on='ID', right_on='Company ID', how='left')\n",
    "\n",
    "# Fill missing values for companies with no founder data\n",
    "companies['executive_ratio'] = companies['executive_ratio'].fillna(0)\n",
    "companies['all_executives'] = companies['all_executives'].fillna(0)\n",
    "companies['any_executive'] = companies['any_executive'].fillna(0)\n",
    "\n",
    "# Drop the redundant Company ID column after merging\n",
    "companies.drop(['Company ID'], axis=1, inplace=True)\n",
    "\n",
    "# Rename columns for better readability\n",
    "companies.rename(columns={\n",
    "    'executive_ratio': 'Executive Ratio',\n",
    "    'all_executives': 'All Executives',\n",
    "    'any_executive': 'Any Executive'\n",
    "}, inplace=True)\n"
   ],
   "id": "a07b6dfd110486a6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature 10-14: Job Durations\n",
    "- Few Years Experience Ratio: Proportion of a company's founders with 1–5 years of total experience.\n",
    "- Decade Experience Ratio: Proportion of a company's founders with 10+ years of total experience.\n",
    "- Mid Career Experience Ratio: Proportion of a company's founders with 5–10 years of total experience.\n",
    "- Avg Gaps in Experience: Average number of months of gaps in career experience per founder in a company.\n",
    "- Avg Longest Position Duration: Average duration (in months) of the longest position held by a founder in a company."
   ],
   "id": "2c6223f95340e8cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:55:50.845381Z",
     "start_time": "2025-01-19T19:55:50.573258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a dictionary to translate German month abbreviations to English\n",
    "MONTHS_TRANSLATION = {\n",
    "    \"Jan.\": \"Jan\", \"Feb.\": \"Feb\", \"März\": \"Mar\", \"Apr.\": \"Apr\",\n",
    "    \"Mai\": \"May\", \"Juni\": \"Jun\", \"Juli\": \"Jul\", \"Aug.\": \"Aug\",\n",
    "    \"Sept.\": \"Sep\", \"Okt.\": \"Oct\", \"Nov.\": \"Nov\", \"Dez.\": \"Dec\"\n",
    "}\n",
    "\n",
    "def translate_months(date_str):\n",
    "    for de, en in MONTHS_TRANSLATION.items():\n",
    "        date_str = date_str.replace(de, en)\n",
    "    return date_str\n",
    "\n",
    "def parse_intervals(row):\n",
    "    intervals = []\n",
    "    for col in row.index:\n",
    "        if \"duration\" in col and isinstance(row[col], str) and row[col].strip():\n",
    "            duration = translate_months(row[col])  # Translate German month names\n",
    "            match = re.match(r\"([\\w.]+ \\d{4}|\\d{4})–(Heute|[\\w.]+ \\d{4}|\\d{4})\", duration)\n",
    "            if match:\n",
    "                start_str, end_str = match.groups()\n",
    "                start_date = parser.parse(start_str, dayfirst=False)\n",
    "                end_date = datetime.now() if end_str == \"Heute\" else parser.parse(end_str, dayfirst=False)\n",
    "                intervals.append((start_date, end_date))\n",
    "    return intervals\n",
    "\n",
    "def merge_intervals(intervals):\n",
    "    if not intervals:\n",
    "        return []\n",
    "    intervals.sort(key=lambda x: x[0])\n",
    "    merged = [intervals[0]]\n",
    "    for current in intervals[1:]:\n",
    "        last = merged[-1]\n",
    "        if current[0] <= last[1]:\n",
    "            merged[-1] = (last[0], max(last[1], current[1]))\n",
    "        else:\n",
    "            merged.append(current)\n",
    "    return merged\n",
    "\n",
    "def calculate_total_months(merged_intervals):\n",
    "    return sum((end.year - start.year) * 12 + (end.month - start.month) for start, end in merged_intervals)\n",
    "\n",
    "def calculate_gaps(merged_intervals):\n",
    "    if len(merged_intervals) < 2:\n",
    "        return 0\n",
    "    gaps = [\n",
    "        (merged_intervals[i][0] - merged_intervals[i-1][1]).days // 30\n",
    "        for i in range(1, len(merged_intervals))\n",
    "    ]\n",
    "    return sum(gaps)\n",
    "\n",
    "# Extract job intervals, merge overlapping intervals, and calculate experience statistics\n",
    "ln_details[\"intervals\"] = ln_details.apply(lambda row: parse_intervals(row), axis=1)\n",
    "ln_details[\"merged_intervals\"] = ln_details[\"intervals\"].apply(merge_intervals)\n",
    "ln_details[\"total_experience_months\"] = ln_details[\"merged_intervals\"].apply(calculate_total_months)\n",
    "ln_details[\"total_experience_years\"] = ln_details[\"total_experience_months\"] / 12\n",
    "ln_details[\"few_years_experience\"] = ln_details[\"total_experience_years\"].apply(lambda x: 1 if 1 <= x <= 5 else 0)\n",
    "ln_details[\"decade_experience\"] = ln_details[\"total_experience_years\"].apply(lambda x: 1 if x >= 10 else 0)\n",
    "ln_details[\"mid_career_experience\"] = ln_details[\"total_experience_years\"].apply(lambda x: 1 if 5 <= x < 10 else 0)\n",
    "ln_details[\"gaps_in_experience\"] = ln_details[\"merged_intervals\"].apply(calculate_gaps)\n",
    "ln_details[\"longest_position_duration\"] = ln_details[\"merged_intervals\"].apply(\n",
    "    lambda intervals: max((end - start).days / 30 for start, end in intervals) if intervals else 0\n",
    ")\n",
    "\n",
    "# Merge experience statistics into the founders data frame\n",
    "founders = founders.merge(\n",
    "    ln_details[[\"url\", \"few_years_experience\", \"decade_experience\",\n",
    "                \"mid_career_experience\", \"gaps_in_experience\",\n",
    "                \"longest_position_duration\"]],\n",
    "    left_on=\"linkedin_url\",\n",
    "    right_on=\"url\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"_founders\", \"_ln_details\")\n",
    ")\n",
    "\n",
    "# Drop redundant columns\n",
    "founders.drop(columns=[\"url\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Aggregate experience statistics at the company level\n",
    "agg_funcs = {\n",
    "    \"few_years_experience\": \"mean\",\n",
    "    \"decade_experience\": \"mean\",\n",
    "    \"mid_career_experience\": \"mean\",\n",
    "    \"gaps_in_experience\": \"mean\",\n",
    "    \"longest_position_duration\": \"mean\"\n",
    "}\n",
    "company_experience_stats = founders.groupby(\"Company ID\").agg(agg_funcs).reset_index()\n",
    "\n",
    "# Rename aggregated columns for clarity\n",
    "company_experience_stats.rename(\n",
    "    columns={\n",
    "        \"few_years_experience\": \"few_years_experience_ratio\",\n",
    "        \"decade_experience\": \"decade_experience_ratio\",\n",
    "        \"mid_career_experience\": \"mid_career_experience_ratio\",\n",
    "        \"gaps_in_experience\": \"avg_gaps_in_experience\",\n",
    "        \"longest_position_duration\": \"avg_longest_position_duration\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# Merge company-level experience statistics into the companies data frame\n",
    "companies[\"ID\"] = companies[\"ID\"].astype(str)\n",
    "company_experience_stats[\"Company ID\"] = company_experience_stats[\"Company ID\"].astype(str)\n",
    "companies = companies.merge(company_experience_stats, left_on=\"ID\", right_on=\"Company ID\", how=\"left\")\n",
    "\n",
    "# Fill missing values and drop redundant columns\n",
    "companies.fillna(0, inplace=True)\n",
    "companies.drop(columns=[\"Company ID\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Rename final columns for readability\n",
    "companies.rename(columns={\n",
    "    'few_years_experience_ratio': 'Few Years Experience Ratio',\n",
    "    'decade_experience_ratio': 'Decade Experience Ratio',\n",
    "    'mid_career_experience_ratio': 'Mid Career Experience Ratio',\n",
    "    'avg_gaps_in_experience': 'Avg Gaps in Experience',\n",
    "    'longest_position_duration': 'Avg Longest Position Duration'\n",
    "}, inplace=True)\n"
   ],
   "id": "db3d29364e652bbd",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Final Removing of Columns",
   "id": "8ec4fd5307018587"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:55:54.478492Z",
     "start_time": "2025-01-19T19:55:54.470782Z"
    }
   },
   "cell_type": "code",
   "source": "companies = companies.drop(['employeeCount', 'employeeCountRange', 'employeeCountRangeMin', 'employeeCountRangeMax', 'account_created', 'Company ID_x'], axis=1)",
   "id": "f2f64cf9b87d36d2",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:55:55.482011Z",
     "start_time": "2025-01-19T19:55:55.450038Z"
    }
   },
   "cell_type": "code",
   "source": "companies",
   "id": "7d7342ba24262350",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          ID Organization Name  \\\n",
       "0     000001             2trde   \n",
       "1     000002     36ZERO Vision   \n",
       "2     000003      3Bears Foods   \n",
       "3     000004           3dTrust   \n",
       "4     000005             abaut   \n",
       "...      ...               ...   \n",
       "1513  001506              SAYM   \n",
       "1514  001507        SONAH GmbH   \n",
       "1515  001508           Taxy.io   \n",
       "1516  001509    TRINKKOST GmbH   \n",
       "1517  001510   worqs Coworking   \n",
       "\n",
       "                                             Industries  \\\n",
       "0                                [Automotive, Software]   \n",
       "1     [Artificial Intelligence (AI), Computer Vision...   \n",
       "2                                   [Food and Beverage]   \n",
       "3                [3D Printing, Manufacturing, Software]   \n",
       "4     [Analytics, Artificial Intelligence (AI), Cons...   \n",
       "...                                                 ...   \n",
       "1513  [Apps, B2B, B2C, Human Resources, Mobile Apps,...   \n",
       "1514  [Apps, Artificial Intelligence (AI), Computer ...   \n",
       "1515  [FinTech, Legal Tech, Machine Learning, Software]   \n",
       "1516  [Agriculture, Consumer Goods, Fitness, Food an...   \n",
       "1517  [Commercial Real Estate, Coworking, Real Estat...   \n",
       "\n",
       "                     Headquarters Location  \\\n",
       "0                  Munich, Bayern, Germany   \n",
       "1                  Munich, Bayern, Germany   \n",
       "2                  Munich, Bayern, Germany   \n",
       "3                  Munich, Bayern, Germany   \n",
       "4                  Munich, Bayern, Germany   \n",
       "...                                    ...   \n",
       "1513  Aachen, Nordrhein-Westfalen, Germany   \n",
       "1514  Aachen, Nordrhein-Westfalen, Germany   \n",
       "1515  Aachen, Nordrhein-Westfalen, Germany   \n",
       "1516  Aachen, Nordrhein-Westfalen, Germany   \n",
       "1517  Aachen, Nordrhein-Westfalen, Germany   \n",
       "\n",
       "                                            Description CB Rank (Company)  \\\n",
       "0     2trde develops a software solution designed fo...            57,123   \n",
       "1     36ZEROVision is an AI-powered visual inspectio...            51,326   \n",
       "2     3Bears Foods enable a balanced and delicious b...           275,817   \n",
       "3     3dTrust helps companies integrate 3D printing ...           134,694   \n",
       "4     abaut builds a SaaS that enables businesses al...           219,525   \n",
       "...                                                 ...               ...   \n",
       "1513  The SAYM platform for swarm mobility defines t...           166,910   \n",
       "1514  SONAH developed a flexible embedded vision sen...           121,752   \n",
       "1515  Taxy.io builds the leading platform for B2B ta...           220,816   \n",
       "1516  TRINKKOST is a food supplement manufacturing c...           907,817   \n",
       "1517                             Coworking, Flex Office           372,043   \n",
       "\n",
       "     Postal Code Founded Date Exit Date                    Website  ...  \\\n",
       "0              0   2017-01-01         0      https://www.2trde.com  ...   \n",
       "1          81671   2019-01-01         0  https://36zerovision.com/  ...   \n",
       "2              0   2015-01-01         0         https://3bears.de/  ...   \n",
       "3          80797   2015-01-01         0          http://3dtrust.de  ...   \n",
       "4          80992   2017-07-21         0           https://abaut.de  ...   \n",
       "...          ...          ...       ...                        ...  ...   \n",
       "1513     52070.0   2019-01-01         0       https://www.saym.io/  ...   \n",
       "1514     52070.0   2016-01-01         0      http://www.sonah.tech  ...   \n",
       "1515     52070.0   2019-01-01         0       https://www.taxy.io/  ...   \n",
       "1516           0   2016-01-01         0    http://www.trinkkost.de  ...   \n",
       "1517     52066.0   2018-04-28         0       https://www.worqs.de  ...   \n",
       "\n",
       "     All Researchers Any Researcher Executive Ratio All Executives  \\\n",
       "0                0.0            0.0        0.000000            0.0   \n",
       "1                1.0            1.0        0.000000            0.0   \n",
       "2                0.0            0.0        0.000000            0.0   \n",
       "3                0.0            1.0        0.666667            0.0   \n",
       "4                0.0            0.0        0.000000            0.0   \n",
       "...              ...            ...             ...            ...   \n",
       "1513             0.0            0.0        0.000000            0.0   \n",
       "1514             0.0            0.0        0.000000            0.0   \n",
       "1515             0.0            1.0        0.333333            0.0   \n",
       "1516             0.0            0.0        0.000000            0.0   \n",
       "1517             0.0            0.0        0.000000            0.0   \n",
       "\n",
       "     Any Executive  Few Years Experience Ratio  Decade Experience Ratio  \\\n",
       "0              0.0                         0.0                 1.000000   \n",
       "1              0.0                         0.0                 1.000000   \n",
       "2              0.0                         0.0                 0.000000   \n",
       "3              1.0                         0.0                 0.666667   \n",
       "4              0.0                         0.0                 0.000000   \n",
       "...            ...                         ...                      ...   \n",
       "1513           0.0                         0.0                 0.000000   \n",
       "1514           0.0                         0.0                 0.000000   \n",
       "1515           1.0                         0.0                 1.000000   \n",
       "1516           0.0                         0.0                 0.000000   \n",
       "1517           0.0                         0.0                 0.000000   \n",
       "\n",
       "     Mid Career Experience Ratio  Avg Gaps in Experience  \\\n",
       "0                       0.000000                0.000000   \n",
       "1                       0.000000                7.000000   \n",
       "2                       0.000000                0.000000   \n",
       "3                       0.333333               15.666667   \n",
       "4                       0.000000                0.000000   \n",
       "...                          ...                     ...   \n",
       "1513                    1.000000               13.000000   \n",
       "1514                    0.000000                0.000000   \n",
       "1515                    0.000000                2.666667   \n",
       "1516                    0.000000                0.000000   \n",
       "1517                    1.000000                0.000000   \n",
       "\n",
       "     avg_longest_position_duration  \n",
       "0                       150.166667  \n",
       "1                        82.233333  \n",
       "2                         0.000000  \n",
       "3                        99.055556  \n",
       "4                         0.000000  \n",
       "...                            ...  \n",
       "1513                     56.833333  \n",
       "1514                      0.000000  \n",
       "1515                    151.888889  \n",
       "1516                      0.000000  \n",
       "1517                     97.400000  \n",
       "\n",
       "[1518 rows x 136 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>Industries</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>CB Rank (Company)</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Founded Date</th>\n",
       "      <th>Exit Date</th>\n",
       "      <th>Website</th>\n",
       "      <th>...</th>\n",
       "      <th>All Researchers</th>\n",
       "      <th>Any Researcher</th>\n",
       "      <th>Executive Ratio</th>\n",
       "      <th>All Executives</th>\n",
       "      <th>Any Executive</th>\n",
       "      <th>Few Years Experience Ratio</th>\n",
       "      <th>Decade Experience Ratio</th>\n",
       "      <th>Mid Career Experience Ratio</th>\n",
       "      <th>Avg Gaps in Experience</th>\n",
       "      <th>avg_longest_position_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>2trde</td>\n",
       "      <td>[Automotive, Software]</td>\n",
       "      <td>Munich, Bayern, Germany</td>\n",
       "      <td>2trde develops a software solution designed fo...</td>\n",
       "      <td>57,123</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.2trde.com</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>36ZERO Vision</td>\n",
       "      <td>[Artificial Intelligence (AI), Computer Vision...</td>\n",
       "      <td>Munich, Bayern, Germany</td>\n",
       "      <td>36ZEROVision is an AI-powered visual inspectio...</td>\n",
       "      <td>51,326</td>\n",
       "      <td>81671</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>https://36zerovision.com/</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>82.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003</td>\n",
       "      <td>3Bears Foods</td>\n",
       "      <td>[Food and Beverage]</td>\n",
       "      <td>Munich, Bayern, Germany</td>\n",
       "      <td>3Bears Foods enable a balanced and delicious b...</td>\n",
       "      <td>275,817</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>https://3bears.de/</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004</td>\n",
       "      <td>3dTrust</td>\n",
       "      <td>[3D Printing, Manufacturing, Software]</td>\n",
       "      <td>Munich, Bayern, Germany</td>\n",
       "      <td>3dTrust helps companies integrate 3D printing ...</td>\n",
       "      <td>134,694</td>\n",
       "      <td>80797</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>http://3dtrust.de</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>99.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005</td>\n",
       "      <td>abaut</td>\n",
       "      <td>[Analytics, Artificial Intelligence (AI), Cons...</td>\n",
       "      <td>Munich, Bayern, Germany</td>\n",
       "      <td>abaut builds a SaaS that enables businesses al...</td>\n",
       "      <td>219,525</td>\n",
       "      <td>80992</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>0</td>\n",
       "      <td>https://abaut.de</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>001506</td>\n",
       "      <td>SAYM</td>\n",
       "      <td>[Apps, B2B, B2C, Human Resources, Mobile Apps,...</td>\n",
       "      <td>Aachen, Nordrhein-Westfalen, Germany</td>\n",
       "      <td>The SAYM platform for swarm mobility defines t...</td>\n",
       "      <td>166,910</td>\n",
       "      <td>52070.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.saym.io/</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>56.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>001507</td>\n",
       "      <td>SONAH GmbH</td>\n",
       "      <td>[Apps, Artificial Intelligence (AI), Computer ...</td>\n",
       "      <td>Aachen, Nordrhein-Westfalen, Germany</td>\n",
       "      <td>SONAH developed a flexible embedded vision sen...</td>\n",
       "      <td>121,752</td>\n",
       "      <td>52070.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.sonah.tech</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>001508</td>\n",
       "      <td>Taxy.io</td>\n",
       "      <td>[FinTech, Legal Tech, Machine Learning, Software]</td>\n",
       "      <td>Aachen, Nordrhein-Westfalen, Germany</td>\n",
       "      <td>Taxy.io builds the leading platform for B2B ta...</td>\n",
       "      <td>220,816</td>\n",
       "      <td>52070.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.taxy.io/</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>151.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>001509</td>\n",
       "      <td>TRINKKOST GmbH</td>\n",
       "      <td>[Agriculture, Consumer Goods, Fitness, Food an...</td>\n",
       "      <td>Aachen, Nordrhein-Westfalen, Germany</td>\n",
       "      <td>TRINKKOST is a food supplement manufacturing c...</td>\n",
       "      <td>907,817</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.trinkkost.de</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>001510</td>\n",
       "      <td>worqs Coworking</td>\n",
       "      <td>[Commercial Real Estate, Coworking, Real Estat...</td>\n",
       "      <td>Aachen, Nordrhein-Westfalen, Germany</td>\n",
       "      <td>Coworking, Flex Office</td>\n",
       "      <td>372,043</td>\n",
       "      <td>52066.0</td>\n",
       "      <td>2018-04-28</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.worqs.de</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1518 rows × 136 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Final Renaming of Columns\n",
   "id": "8c9aeb3f77909734"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:55:57.724763Z",
     "start_time": "2025-01-19T19:55:57.718683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "companies.rename(columns={\n",
    "    'followers': 'LinkedIn: Followers',\n",
    "    'followers_Twitter': 'X: Followers',\n",
    "    'following': 'X: Following',\n",
    "    'tweets': 'X: Number of Tweets',\n",
    "    'account_age_days': 'X: Account Age Days',\n",
    "    'tweet_activity': 'X: Tweet Activity',\n",
    "    'followers_max_growth': 'X: Followers Max Growth',\n",
    "    'followers_max_loss': 'X: Followers Max Loss',\n",
    "    'tweets_max_growth': 'X: Tweets Max Growth',\n",
    "    'tweets_max_loss': 'X: Tweets Max Loss',\n",
    "'average_linkedin_followers_founders': 'LinkedIn: Average Followers Founders',\n",
    "    'average_linkedin_connections_founders': 'LinkedIn: Average Connections Founders',\n",
    "'min_linkedin_followers_founders': 'LinkedIn: Min Followers Founders', 'max_linkedin_followers_founders': 'LinkedIn: Max Followers Founders',\n",
    "    'min_linkedin_connections_founders': 'LinkedIn: Min Connections Founders', 'max_linkedin_connections_founders': 'LinkedIn: Max Connections Founders', 'Highest Education_Bachelor': 'Highest Education Bachelor', 'Highest Education_Doctor/PhD': 'Highest Education Doctor/PhD', 'Highest Education_Master': 'Highest Education Master', 'avg_longest_position_duration': 'Avg Longest Position Duration'\n",
    "''}, inplace= True)\n"
   ],
   "id": "72a917d1d37d0a5e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Final Check",
   "id": "e82c0d7efcf64ecb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:55:59.617014Z",
     "start_time": "2025-01-19T19:55:59.609129Z"
    }
   },
   "cell_type": "code",
   "source": "companies = companies.drop_duplicates(subset='Organization Name', keep='first')",
   "id": "f0dd3fa2dcd8d7e9",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:56:00.723424Z",
     "start_time": "2025-01-19T19:56:00.649874Z"
    }
   },
   "cell_type": "code",
   "source": "companies.to_csv('companies.csv', index=False)",
   "id": "ace122759be41aef",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:56:01.500759Z",
     "start_time": "2025-01-19T19:56:01.487186Z"
    }
   },
   "cell_type": "code",
   "source": "companies",
   "id": "72636e2d714fb931",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          ID Organization Name  \\\n",
       "0     000001             2trde   \n",
       "1     000002     36ZERO Vision   \n",
       "2     000003      3Bears Foods   \n",
       "3     000004           3dTrust   \n",
       "4     000005             abaut   \n",
       "...      ...               ...   \n",
       "1513  001506              SAYM   \n",
       "1514  001507        SONAH GmbH   \n",
       "1515  001508           Taxy.io   \n",
       "1516  001509    TRINKKOST GmbH   \n",
       "1517  001510   worqs Coworking   \n",
       "\n",
       "                                             Industries  \\\n",
       "0                                [Automotive, Software]   \n",
       "1     [Artificial Intelligence (AI), Computer Vision...   \n",
       "2                                   [Food and Beverage]   \n",
       "3                [3D Printing, Manufacturing, Software]   \n",
       "4     [Analytics, Artificial Intelligence (AI), Cons...   \n",
       "...                                                 ...   \n",
       "1513  [Apps, B2B, B2C, Human Resources, Mobile Apps,...   \n",
       "1514  [Apps, Artificial Intelligence (AI), Computer ...   \n",
       "1515  [FinTech, Legal Tech, Machine Learning, Software]   \n",
       "1516  [Agriculture, Consumer Goods, Fitness, Food an...   \n",
       "1517  [Commercial Real Estate, Coworking, Real Estat...   \n",
       "\n",
       "                     Headquarters Location  \\\n",
       "0                  Munich, Bayern, Germany   \n",
       "1                  Munich, Bayern, Germany   \n",
       "2                  Munich, Bayern, Germany   \n",
       "3                  Munich, Bayern, Germany   \n",
       "4                  Munich, Bayern, Germany   \n",
       "...                                    ...   \n",
       "1513  Aachen, Nordrhein-Westfalen, Germany   \n",
       "1514  Aachen, Nordrhein-Westfalen, Germany   \n",
       "1515  Aachen, Nordrhein-Westfalen, Germany   \n",
       "1516  Aachen, Nordrhein-Westfalen, Germany   \n",
       "1517  Aachen, Nordrhein-Westfalen, Germany   \n",
       "\n",
       "                                            Description CB Rank (Company)  \\\n",
       "0     2trde develops a software solution designed fo...            57,123   \n",
       "1     36ZEROVision is an AI-powered visual inspectio...            51,326   \n",
       "2     3Bears Foods enable a balanced and delicious b...           275,817   \n",
       "3     3dTrust helps companies integrate 3D printing ...           134,694   \n",
       "4     abaut builds a SaaS that enables businesses al...           219,525   \n",
       "...                                                 ...               ...   \n",
       "1513  The SAYM platform for swarm mobility defines t...           166,910   \n",
       "1514  SONAH developed a flexible embedded vision sen...           121,752   \n",
       "1515  Taxy.io builds the leading platform for B2B ta...           220,816   \n",
       "1516  TRINKKOST is a food supplement manufacturing c...           907,817   \n",
       "1517                             Coworking, Flex Office           372,043   \n",
       "\n",
       "     Postal Code Founded Date Exit Date                    Website  ...  \\\n",
       "0              0   2017-01-01         0      https://www.2trde.com  ...   \n",
       "1          81671   2019-01-01         0  https://36zerovision.com/  ...   \n",
       "2              0   2015-01-01         0         https://3bears.de/  ...   \n",
       "3          80797   2015-01-01         0          http://3dtrust.de  ...   \n",
       "4          80992   2017-07-21         0           https://abaut.de  ...   \n",
       "...          ...          ...       ...                        ...  ...   \n",
       "1513     52070.0   2019-01-01         0       https://www.saym.io/  ...   \n",
       "1514     52070.0   2016-01-01         0      http://www.sonah.tech  ...   \n",
       "1515     52070.0   2019-01-01         0       https://www.taxy.io/  ...   \n",
       "1516           0   2016-01-01         0    http://www.trinkkost.de  ...   \n",
       "1517     52066.0   2018-04-28         0       https://www.worqs.de  ...   \n",
       "\n",
       "     All Researchers Any Researcher Executive Ratio All Executives  \\\n",
       "0                0.0            0.0        0.000000            0.0   \n",
       "1                1.0            1.0        0.000000            0.0   \n",
       "2                0.0            0.0        0.000000            0.0   \n",
       "3                0.0            1.0        0.666667            0.0   \n",
       "4                0.0            0.0        0.000000            0.0   \n",
       "...              ...            ...             ...            ...   \n",
       "1513             0.0            0.0        0.000000            0.0   \n",
       "1514             0.0            0.0        0.000000            0.0   \n",
       "1515             0.0            1.0        0.333333            0.0   \n",
       "1516             0.0            0.0        0.000000            0.0   \n",
       "1517             0.0            0.0        0.000000            0.0   \n",
       "\n",
       "     Any Executive  Few Years Experience Ratio  Decade Experience Ratio  \\\n",
       "0              0.0                         0.0                 1.000000   \n",
       "1              0.0                         0.0                 1.000000   \n",
       "2              0.0                         0.0                 0.000000   \n",
       "3              1.0                         0.0                 0.666667   \n",
       "4              0.0                         0.0                 0.000000   \n",
       "...            ...                         ...                      ...   \n",
       "1513           0.0                         0.0                 0.000000   \n",
       "1514           0.0                         0.0                 0.000000   \n",
       "1515           1.0                         0.0                 1.000000   \n",
       "1516           0.0                         0.0                 0.000000   \n",
       "1517           0.0                         0.0                 0.000000   \n",
       "\n",
       "     Mid Career Experience Ratio  Avg Gaps in Experience  \\\n",
       "0                       0.000000                0.000000   \n",
       "1                       0.000000                7.000000   \n",
       "2                       0.000000                0.000000   \n",
       "3                       0.333333               15.666667   \n",
       "4                       0.000000                0.000000   \n",
       "...                          ...                     ...   \n",
       "1513                    1.000000               13.000000   \n",
       "1514                    0.000000                0.000000   \n",
       "1515                    0.000000                2.666667   \n",
       "1516                    0.000000                0.000000   \n",
       "1517                    1.000000                0.000000   \n",
       "\n",
       "     Avg Longest Position Duration  \n",
       "0                       150.166667  \n",
       "1                        82.233333  \n",
       "2                         0.000000  \n",
       "3                        99.055556  \n",
       "4                         0.000000  \n",
       "...                            ...  \n",
       "1513                     56.833333  \n",
       "1514                      0.000000  \n",
       "1515                    151.888889  \n",
       "1516                      0.000000  \n",
       "1517                     97.400000  \n",
       "\n",
       "[1510 rows x 136 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>Industries</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Description</th>\n",
       "      <th>CB Rank (Company)</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Founded Date</th>\n",
       "      <th>Exit Date</th>\n",
       "      <th>Website</th>\n",
       "      <th>...</th>\n",
       "      <th>All Researchers</th>\n",
       "      <th>Any Researcher</th>\n",
       "      <th>Executive Ratio</th>\n",
       "      <th>All Executives</th>\n",
       "      <th>Any Executive</th>\n",
       "      <th>Few Years Experience Ratio</th>\n",
       "      <th>Decade Experience Ratio</th>\n",
       "      <th>Mid Career Experience Ratio</th>\n",
       "      <th>Avg Gaps in Experience</th>\n",
       "      <th>Avg Longest Position Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001</td>\n",
       "      <td>2trde</td>\n",
       "      <td>[Automotive, Software]</td>\n",
       "      <td>Munich, Bayern, Germany</td>\n",
       "      <td>2trde develops a software solution designed fo...</td>\n",
       "      <td>57,123</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.2trde.com</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002</td>\n",
       "      <td>36ZERO Vision</td>\n",
       "      <td>[Artificial Intelligence (AI), Computer Vision...</td>\n",
       "      <td>Munich, Bayern, Germany</td>\n",
       "      <td>36ZEROVision is an AI-powered visual inspectio...</td>\n",
       "      <td>51,326</td>\n",
       "      <td>81671</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>https://36zerovision.com/</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>82.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003</td>\n",
       "      <td>3Bears Foods</td>\n",
       "      <td>[Food and Beverage]</td>\n",
       "      <td>Munich, Bayern, Germany</td>\n",
       "      <td>3Bears Foods enable a balanced and delicious b...</td>\n",
       "      <td>275,817</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>https://3bears.de/</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004</td>\n",
       "      <td>3dTrust</td>\n",
       "      <td>[3D Printing, Manufacturing, Software]</td>\n",
       "      <td>Munich, Bayern, Germany</td>\n",
       "      <td>3dTrust helps companies integrate 3D printing ...</td>\n",
       "      <td>134,694</td>\n",
       "      <td>80797</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>http://3dtrust.de</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>99.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005</td>\n",
       "      <td>abaut</td>\n",
       "      <td>[Analytics, Artificial Intelligence (AI), Cons...</td>\n",
       "      <td>Munich, Bayern, Germany</td>\n",
       "      <td>abaut builds a SaaS that enables businesses al...</td>\n",
       "      <td>219,525</td>\n",
       "      <td>80992</td>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>0</td>\n",
       "      <td>https://abaut.de</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>001506</td>\n",
       "      <td>SAYM</td>\n",
       "      <td>[Apps, B2B, B2C, Human Resources, Mobile Apps,...</td>\n",
       "      <td>Aachen, Nordrhein-Westfalen, Germany</td>\n",
       "      <td>The SAYM platform for swarm mobility defines t...</td>\n",
       "      <td>166,910</td>\n",
       "      <td>52070.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.saym.io/</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>56.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>001507</td>\n",
       "      <td>SONAH GmbH</td>\n",
       "      <td>[Apps, Artificial Intelligence (AI), Computer ...</td>\n",
       "      <td>Aachen, Nordrhein-Westfalen, Germany</td>\n",
       "      <td>SONAH developed a flexible embedded vision sen...</td>\n",
       "      <td>121,752</td>\n",
       "      <td>52070.0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.sonah.tech</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>001508</td>\n",
       "      <td>Taxy.io</td>\n",
       "      <td>[FinTech, Legal Tech, Machine Learning, Software]</td>\n",
       "      <td>Aachen, Nordrhein-Westfalen, Germany</td>\n",
       "      <td>Taxy.io builds the leading platform for B2B ta...</td>\n",
       "      <td>220,816</td>\n",
       "      <td>52070.0</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.taxy.io/</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>151.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>001509</td>\n",
       "      <td>TRINKKOST GmbH</td>\n",
       "      <td>[Agriculture, Consumer Goods, Fitness, Food an...</td>\n",
       "      <td>Aachen, Nordrhein-Westfalen, Germany</td>\n",
       "      <td>TRINKKOST is a food supplement manufacturing c...</td>\n",
       "      <td>907,817</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.trinkkost.de</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>001510</td>\n",
       "      <td>worqs Coworking</td>\n",
       "      <td>[Commercial Real Estate, Coworking, Real Estat...</td>\n",
       "      <td>Aachen, Nordrhein-Westfalen, Germany</td>\n",
       "      <td>Coworking, Flex Office</td>\n",
       "      <td>372,043</td>\n",
       "      <td>52066.0</td>\n",
       "      <td>2018-04-28</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.worqs.de</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1510 rows × 136 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
